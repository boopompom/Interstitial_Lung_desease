# README 

## file description

## model and weights
     ILD_CNN_model.json 
     ILD_CNN_model_weights 
those files contain the model used (one needs to compile it after upload) and the weights coming from a training session with 100 Epochs

### prediction part notebook
the file name is ILD_CNN Predict part.ipynb
this notebook load the model and the weights trained in the former training session.
Then it compiles it with the same compile paramenters as in the training session.
It load the test set as the pto-be-predicted set and calculates the classification and the probabilities

for the purpose of this prediction, other files needed to be updated. They are main4.py, cnn_model4.py, ild_helpers.py


### model saving and reloading check
Model predict-complex case.ipynb
this notebook uses the cifar10 dataset (chosen for convenience) and a simple model is trained on a single epoch.
Then the model and the generated weights are saved and reloaded again. Both models (presaved and reloaded) are then compiled and the predict method is used on a simplistic test set and result compared. 


### pickl files
X_train.pkl
X_val.pkl
X_test.pkl
y_train.pkl
y_val.pkl
y_test.pkl
these files are generated by the jupyter notebook dataset Creation.
They are used as dataset for the CNN, however only the _train and _val sets are currently used.
The _test sets should be used for final assessment.

### main4.py
this is the top python file to be called to run the CNN training
the file calls the ild_helpers.py and the cnn_model4.py files

### ild_helpers.py
essentially to load the data 

### cnn_model4.py
defines the used model and compiles it

### dataset Creation.ipynb
reads the directory structure of the preprocessed .bmp formatted files and loads them.
pickl files are generated 


### Tools used:
1.	RadianDICOM viewer to view dcm files.
  a)	Can also convert dicom images in jpg, bmp,
2.	Total Image Converter to create jpeg, bpm and JPEG 2000 from dcm. I have created in each  ILD_DB-textROIs dataset (35, 65,…) the directories bmp,jp2k,jpg to store equivalent format from dcm files.
3.	Spyder Python 3.5 for Python

### To run the patch generator
1.	3 python files needed:
  a.	final.py (this is the top, parameters are defined in it, no need to touch the 2 others)
  b.	fillshape.py
  c.	generatetabc.py
2.	Preparation
  To run the patch generator, we need first to have the directory ILD_DB-textROIs in the place where Python  is launched.
  In each dataset in directory ILD_DB-textROIs, we need to add a directory named bmp or jpg to store bmp or jpg files generated from dcm
3.	Customization in final.py
  a.	Patch image format: bmp or jpg
  b.	Dicom file size: 512 * 512
  c.	Patch size: 32*32
  d.	Threshold  in % : 0.8 for patch area over ROI
  
### program generate files
1. From where it is launched:
  e.	‘Jpeg’ directory , where jpeg images and text files of all ROI with patches is stored
  f.	‘patch’ directory, where patches are store in sub directories, named after label and localization names in each scan, according to image format declared in top python (jpg or bmp). I think bmp is more accurate.
2.	in each ILD_DB-textROIs dataset (35, 65,…) , a directory named ‘patchfile’  where intermediate data is  stored. Can be deleted afterward.

### Database Analysis
1.	The Dcm files are identical in ILD_DB_txtROIs, ILD_DB_volumeROIs   and  ILD_DB_lungMasks
2.	A ROI text file is in each data set In ILD_DB_txtROIs This Text file: corresponds to ROI in ILD_DB_volumeROIs  roi_mask of each dataset.
3.	There is a set of ROI in roi_mask in each dataset of ILD_DB_lungMasks: this is lung area 

